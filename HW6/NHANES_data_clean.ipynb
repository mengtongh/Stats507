{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bc8977",
   "metadata": {},
   "source": [
    "# STATS507 HW 2\n",
    "### **Mengtong Hu**  \n",
    "### *September 30, 2021*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "99992107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import Timer\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db1817",
   "metadata": {},
   "source": [
    "### Question 0\n",
    "## a. \n",
    "The code takes a list of tuples and returns the tuple with the largest ending value/or the $n$th values, grouping by the same starting value/or the $m$th value\n",
    "## b. There are a few errors in the code snippet. First, the indentation of\n",
    "1. Line 4 and 5 should be aligned. \n",
    "2. in line 7, the second index cannot exceed 2 which is one less than the length of a tuple from the sample_list.\n",
    "3. The inner loop can start with m+1 instead of going through all tuples in the list. The current implementation is inefficient where same comparisons are considered twice. \n",
    "4. The naming of variables in the code does not convey much useful information on what they serve for and can be improved by using more meaningful names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898ab2c",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed5f376a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_n_tuplesofk(n, k=4, low=1 , high=100):\n",
    "    \"\"\"\n",
    "    Return a list of n k-tuples of integers between low and high \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : number of k-tuples \n",
    "    \n",
    "    k : number of elements in a tuple, Default = 4\n",
    "    \n",
    "    low : lower bound of an integer value in the tuple, Default =1\n",
    "    \n",
    "    high : upper bound of an integer value in the tuple, Default = 100\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : a list of n k-tuples\n",
    "          \n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=1055)\n",
    "    result = [tuple(rng.integers(low=0, high=10, size=k)) for _ in range(n)]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34934444",
   "metadata": {},
   "source": [
    "Test if `generate_n_tuplesofk` returns a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca826daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_lst = generate_n_tuplesofk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "585e4a1c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "assert type(tuple_lst) is list and all(type(ele) is tuple for \n",
    "                                       ele in tuple_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006a5d73",
   "metadata": {},
   "source": [
    "Assert statement returns no errors, meaning the function returns a list of tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09de91",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    " Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0f8ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is : [(1, 9, 9), (1, 7, 9), (0, 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "def get_tuple_with_highest_value_by_idx(sample_list, low_idx, high_idx):\n",
    "    \"\"\"\n",
    "    The code takes a list of tuples and returns \n",
    "    the tuple with the largest element at the high_idx,\n",
    "    grouping by the elements at the low_idx. The method\n",
    "    is modified based on the orignal snippet\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_list: a list of tuples with the same length\n",
    "    \n",
    "    low_idx : the idx for grouping by\n",
    "    \n",
    "    high_idx : the idx at which tuples are compared\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : a list of selected tuples\n",
    "          \n",
    "    \"\"\"\n",
    "    op = []\n",
    "    for m in range(len(sample_list)):\n",
    "            li = [sample_list[m]]\n",
    "            for n in range(len(sample_list)):\n",
    "                if (sample_list[m][low_idx] == sample_list[n][low_idx] and\n",
    "                        sample_list[m][high_idx] != sample_list[n][high_idx]):\n",
    "                        li.append(sample_list[n])\n",
    "            op.append(sorted(li, key=lambda dd: dd[2], reverse=True)[0])\n",
    "    res = list(set(op))\n",
    "    return(res)\n",
    "sample_list = [(1, 3, 7), (0, 1, 2), (1, 9, 8),\n",
    "               (1,3,4),(1,9,9),(1,2,3),(1,7,9)]\n",
    "print( \"The result is :\"\n",
    "      ,get_tuple_with_highest_value_by_idx(sample_list, 0 ,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed916555",
   "metadata": {},
   "source": [
    "part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c2f25e6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is:  [(1, 9, 9), (1, 7, 9), (0, 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "def get_tuple_with_highest_value_by_idx_improved(sample_list, low_idx,\n",
    "                                                 high_idx):\n",
    "    \"\"\"\n",
    "    The code takes a list of tuples and returns \n",
    "    the tuple with the largest element at the high_idx,\n",
    "    grouping by the elements at the low_idx. The method is \n",
    "    an improved version based on \n",
    "    `get_tuple_with_highest_value_by_idx`\n",
    "    More efficient for-loop structures are considered\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_list: a list of tuples with the same length\n",
    "    \n",
    "    low_idx : the idx for grouping by\n",
    "    \n",
    "    high_idx : the idx at which tuples are compared\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : a list of selected tuples\n",
    "    \"\"\"      \n",
    "    n = len(sample_list)\n",
    "    result = []\n",
    "    visited=set()\n",
    "    for i in range(n):\n",
    "        if sample_list[i][low_idx] not in visited:\n",
    "            visited.add(sample_list[i][low_idx])\n",
    "            current = [sample_list[i]]\n",
    "            for j in range(i+1,n):\n",
    "                if current[-1][low_idx] == sample_list[j][low_idx]:\n",
    "                    if current[-1][high_idx] < sample_list[j][high_idx]:\n",
    "                        current = [sample_list[j]]\n",
    "                    if current[-1][high_idx] == sample_list[j][high_idx]:\n",
    "                        current.append( sample_list[j]) \n",
    "            \n",
    "            result+=list(set(current))\n",
    "    \n",
    "    \n",
    "    return(result)\n",
    "print(\"The result is: \"\n",
    "      , get_tuple_with_highest_value_by_idx_improved(sample_list, 0 ,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba05c39f",
   "metadata": {},
   "source": [
    "Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "76c8a084",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is:  [(1, 9, 9), (1, 7, 9), (0, 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "def get_tuple_with_highest_value_by_idx_o_n(sample_list, low_idx, high_idx):\n",
    "    \"\"\"\n",
    "    The code takes a list of tuples and returns \n",
    "    the tuple with the largest element at the high_idx,\n",
    "    grouping by the elements at the low_idx. The method \n",
    "    uses dictionary as data structure which has complexity of\n",
    "    'O(n)'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_list: a list of tuples with the same length\n",
    "    \n",
    "    low_idx : the idx for grouping by\n",
    "    \n",
    "    high_idx : the idx at which tuples are compared\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : a list of selected tuples\n",
    "    \"\"\"    \n",
    "    result = {}\n",
    "    for i in range(len(sample_list)):\n",
    "        cur_low_value = sample_list[i][low_idx]\n",
    "        if cur_low_value not in result:\n",
    "            result[cur_low_value] = [sample_list[i]]\n",
    "        else: \n",
    "            if sample_list[i][high_idx] > result[cur_low_value][-1][high_idx]:\n",
    "                result[cur_low_value] = [sample_list[i]] \n",
    "            elif sample_list[i][high_idx] == result[cur_low_value\n",
    "                                                    ][-1][high_idx]: \n",
    "                result[cur_low_value].append(sample_list[i])\n",
    "    \n",
    "    return([tup for lst in result.values() for tup in lst])\n",
    "print(\"The result is: \"\n",
    "      , get_tuple_with_highest_value_by_idx_o_n(sample_list, 0 ,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23a776",
   "metadata": {},
   "source": [
    "In the monte-carlo experiment, I randomly generated 100 tuple lists with 5 tuples in each and tested for the running times of the three methods. The results ouput the average runtime and variance for 100 monte-carlo expeirments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a3c5a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_lst = generate_n_tuplesofk(10)\n",
    "low_idx = 0\n",
    "high_idx = 2\n",
    "n = 10\n",
    "function_lst = ['Original Snippet O(n^2)', 'Improved Snippet O(n^2)',\n",
    "                'Improved Method O(n)' ]\n",
    "time_lst_mean = defaultdict(list)\n",
    "time_lst_n = defaultdict(list)\n",
    "for rep in range(100):\n",
    "    rnd_lst = generate_n_tuplesofk(n)\n",
    "    for idx , f in enumerate([get_tuple_with_highest_value_by_idx, \n",
    "         get_tuple_with_highest_value_by_idx_improved, \n",
    "         get_tuple_with_highest_value_by_idx_o_n]):\n",
    "        t = Timer ('f(sample, a, b)', globals={'f':f, 'sample':rnd_lst,\n",
    "                                           'a':low_idx, 'b': high_idx})\n",
    "        \n",
    "        time_lst_n[function_lst[idx]].append(t.timeit())\n",
    "for func_name in function_lst:\n",
    "    time_lst_mean[func_name] = [np.mean(time_lst_n[func_name])]\n",
    "    time_lst_mean[func_name].append(np.var(time_lst_n[func_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f78d6868",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean runtime</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Snippet O(n^2)</th>\n",
       "      <td>25.269254</td>\n",
       "      <td>0.212552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Improved Snippet O(n^2)</th>\n",
       "      <td>10.746367</td>\n",
       "      <td>0.061537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Improved Method O(n)</th>\n",
       "      <td>4.167102</td>\n",
       "      <td>0.012206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_lst_mean_tb = pd.DataFrame.from_dict(time_lst_mean, orient = 'index',\n",
    "                                         columns=['mean runtime', 'variance'])\n",
    "display(HTML(time_lst_mean_tb.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56020be1",
   "metadata": {},
   "source": [
    "Out of 100 monte-carlo expeirments of tuple size equal to 10, the run time of the Improved Method has less runtime compared to the orignal snippet and the improved snippet. The variance is within acceptable range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5390280",
   "metadata": {},
   "source": [
    "### Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "802974f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['SEQN', 'RIDAGEYR','RIDRETH3','DMDEDUC2','DMDMARTL','RIDSTATR', \n",
    "          'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d6537684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset with the specified fields\n",
    "df1112 = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT')[fields]\n",
    "df1112['cohort'] = '2011-2012'\n",
    "df1314 = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT')[fields]\n",
    "df1314['cohort'] = '2013-2014'\n",
    "df1516 = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT')[fields]\n",
    "df1516['cohort'] = '2015-2016'\n",
    "\n",
    "df1718 = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT')[fields]\n",
    "df1718['cohort'] = '2017-2018'\n",
    "Demo = df1112.append(df1314).append(df1516).append(df1718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ff1b05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables\n",
    "Demo = Demo.rename({'SEQN' : 'id' , 'RIDAGEYR' : 'age','RIDRETH3' : 'race and ethnicity'\n",
    "             ,'DMDEDUC2' : 'education','DMDMARTL' : 'marital status',\n",
    "             'RIDSTATR' : 'interview exam status', 'SDMVPSU' : 'psu', \n",
    "             'SDMVSTRA' : 'stratum', 'WTMEC2YR' : 'two year mec wt' , 'WTINT2YR' :\n",
    "            'twoyr_interview_wt'}, axis = 1)\n",
    "# Changed variables for appropriate category names\n",
    "Demo['race and ethnicity'] = pd.Categorical(Demo['race and ethnicity'].replace(\n",
    "    {1: 'Mexican American', \n",
    "     2: 'Other Hispanic', \n",
    "     3: 'Non-Hispanic White',\n",
    "     4: 'Non-Hispanic Black',\n",
    "     6: 'Non-Hispanic Asian',\n",
    "     7: 'Other Race - Including Multi-Racial',\n",
    "    -1: 'Missing'}))\n",
    "\n",
    "Demo['education'] = pd.Categorical(Demo['education'].replace(\n",
    "    {1: 'Less than 9th grade', \n",
    "     2: '9-11th grade (Includes 12th grade with no diploma)', \n",
    "     3: 'High school graduate/GED or equivalent',\n",
    "     4: 'Some college or AA degree',\n",
    "     5: 'College graduate or above',\n",
    "     7: 'Refused',\n",
    "     9: 'Unknown',\n",
    "    -1: 'Missing'}))\n",
    "\n",
    "Demo['marital status'] = pd.Categorical(Demo['marital status'].replace(\n",
    "    {1: 'Married', \n",
    "     2: 'Widowed', \n",
    "     3: 'Divorced',\n",
    "     4: 'Separated',\n",
    "     5: 'Never married',\n",
    "     6: 'Living with partner',\n",
    "     77: 'Refused',\n",
    "     99: 'Unknown',\n",
    "    -1: 'Missing'}))\n",
    "\n",
    "Demo['interview exam status'] = pd.Categorical(Demo['interview exam status'].replace(\n",
    "    {1: 'Interviewed only', \n",
    "     2: 'Both interviewed and MEC examined', \n",
    "    -1: 'Missing'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4c9f78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the rest of the float varaibels into integer variables \n",
    "fields_to_int = ['id', 'age', 'psu', 'stratum']\n",
    "Demo[fields_to_int] =Demo[fields_to_int].applymap(np.int32)\n",
    "Demo.to_pickle('./Demo_pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962a273",
   "metadata": {},
   "source": [
    "The Denitition Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1144ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/sas/sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset \n",
    "df1112_dent = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "829010e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the fields we are interested in\n",
    "fields_dent = ['SEQN','OHDDESTS'] + [ele for ele in df1112_dent.columns.values[4:64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1ef855c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1112_dent = df1112_dent[fields_dent]\n",
    "df1314_dent = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT')[fields_dent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ea187af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1516_dent = pd.read_sas(\n",
    "      'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT')[fields_dent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fe0e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1718_dent = pd.read_sas(\n",
    "    'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT')[fields_dent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cdb7ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an indictor 'cohort' for the year of the sampling\n",
    "df1112_dent['cohort'] = '2011-2012'\n",
    "df1314_dent['cohort'] = '2013-2014'\n",
    "df1516_dent['cohort'] = '2015-2016'\n",
    "df1718_dent['cohort'] = '2017-2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "73ee9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dent = df1112_dent.append(df1314_dent).append(df1516_dent).append(df1718_dent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4359bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data column names to lower case \n",
    "Dent.columns = Dent.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "769c7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create naming dictionaries for all data column \n",
    "d1 = {'seqn':'id','ohddests':'dentition status code'}\n",
    "d2 = dict(zip(Dent.columns[2:34], \n",
    "             ['tooth count {}'.format(x+1) for x in range(len(Dent.columns[2:34]))]))\n",
    "\n",
    "d3 = dict(zip(Dent.columns[34:48], \n",
    "             ['Coronal Caries Tooth Count {}'.format(x+2) for x in range(len(Dent.columns[34:48]))]))\n",
    "\n",
    "d4 = dict(zip(Dent.columns[49:64], \n",
    "             ['Coronal Caries Tooth Count {}'.format(x) for x in range(19,32)]))\n",
    "d1.update(d2)\n",
    "d1.update(d3)\n",
    "d1.update(d4)\n",
    "# Rename the data columns\n",
    "Dent = Dent.rename(d1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "22ead746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add category names for the categorical variables\n",
    "Dent['dentition status code'] = pd.Categorical(Dent['dentition status code']\n",
    "                            .replace({1: 'Complete', 2: 'Partial', 3:'Not Done'}))\n",
    "for i in range(2, 34):\n",
    "    Dent[str(Dent.columns[i])] = pd.Categorical(Dent[str(Dent.columns[i])].replace(\n",
    "        {1: 'Primary tooth (deciduous) present',\n",
    "         2: 'Permanent tooth present', \n",
    "         3: 'Dental implant',\n",
    "         4: 'Tooth not present', \n",
    "         5: 'Permanent dental root fragment present',\n",
    "         9: 'Could not assess',\n",
    "        -1: 'Missing'}))\n",
    "\n",
    "for i in range(34, 62):\n",
    "    Dent[str(Dent.columns[i])] = pd.Categorical(Dent[str(Dent.columns[i])].replace(\n",
    "        {b'D': 'Sound primary tooth',\n",
    "         b'E': 'Missing due to dental disease', \n",
    "         b'J': 'Permanent root tip is present but no restorative replacement is present',\n",
    "         b'K': 'Primary tooth with surface condition (s)', \n",
    "         b'M': 'Missing due to other causes',\n",
    "         b'P': 'Missing due to dental disease but replaced by a removable restoration',\n",
    "         b'Q': 'Missing due to other causes but replaced by a removable restoration',\n",
    "         b'R': 'Missing due to dental disease, but replaced by a fixed restoration',\n",
    "         b'S': 'Sound permanent tooth',\n",
    "         b'T': 'Permanent root tip is present but a restorative replacement is present',\n",
    "         b'U': 'Unerupted',\n",
    "         b'X': 'Missing due to other causes, but replaced by a fixed restoration',\n",
    "         b'Y': 'Tooth present, condition cannot be assessed',\n",
    "         b'Z': 'Permanent tooth with surface condition (s)',\n",
    "         b'': 'Missing'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1dea560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a pickle object\n",
    "fields_to_int = ['id']\n",
    "Dent[fields_to_int] =Dent[fields_to_int].applymap(np.int32)\n",
    "Dent.to_pickle('./Dent_pickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2411c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cases in the NHANES demographic  datasets from 2011 to 2018 is: 39156\n",
      "The number of cases in the NHANES oral health  and dentition datasets from 2011 to 2018 is: 35909\n"
     ]
    }
   ],
   "source": [
    "print('The number of cases in the NHANES demographic ',\n",
    "      'datasets from 2011 to 2018 is:',Demo['id'].nunique())\n",
    "print('The number of cases in the NHANES oral health ', \n",
    "      'and dentition datasets from 2011 to 2018 is:',Dent['id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca14f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "notebook_metadata_filter": "markdown"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "markdown": {
   "extensions": "footnotes"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
